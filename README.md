# ğŸš€ Sistema de Registro de Boletos de Alta Performance

Sistema de registro de boletos bancÃ¡rios desenvolvido com **Spring Boot 4.0** e **Java 21**, projetado para processar **alto volume de transaÃ§Ãµes** com otimizaÃ§Ãµes de performance e throughput.

## ğŸ“‹ Ãndice

- [VisÃ£o Geral](#-visÃ£o-geral)
- [Recursos Principais](#-recursos-principais)
- [Arquitetura](#-arquitetura)
- [Tecnologias Utilizadas](#-tecnologias-utilizadas)
- [PrÃ©-requisitos](#-prÃ©-requisitos)
- [InstalaÃ§Ã£o e ConfiguraÃ§Ã£o](#-instalaÃ§Ã£o-e-configuraÃ§Ã£o)
- [Como Usar](#-como-usar)
- [API Endpoints](#-api-endpoints)
- [OtimizaÃ§Ãµes de Performance](#-otimizaÃ§Ãµes-de-performance)
- [Estrutura do Projeto](#-estrutura-do-projeto)
- [ConfiguraÃ§Ãµes](#-configuraÃ§Ãµes)

---

## ğŸ¯ VisÃ£o Geral

Este projeto implementa um sistema de registro de boletos bancÃ¡rios otimizado para **alta performance e throughput**, capaz de processar milhÃµes de requisiÃ§Ãµes de forma eficiente atravÃ©s de tÃ©cnicas avanÃ§adas de processamento em lote e mensageria assÃ­ncrona.

### Principais CaracterÃ­sticas

- âœ… **Processamento em Lote (Batch Processing)**: Agrupa atÃ© 10.000 boletos antes de enviar ao Kafka
- âœ… **Virtual Threads (Java 21)**: Utiliza threads virtuais para melhor escalabilidade
- âœ… **Apache Kafka**: Mensageria assÃ­ncrona para desacoplamento e alta disponibilidade
- âœ… **Buffer Concorrente**: Fila thread-safe para acumular requisiÃ§Ãµes
- âœ… **Agendamento AutomÃ¡tico**: Processamento periÃ³dico a cada 500ms
- âœ… **API RESTful**: Interface HTTP para registro de boletos
- âœ… **Monitoramento**: Endpoint para verificar tamanho do buffer

---

## ğŸŒŸ Recursos Principais

### 1. **Processamento em Lote (Batch Processing)**

O sistema utiliza um **buffer interno** (`ConcurrentLinkedQueue`) para acumular boletos recebidos via API. Quando o buffer atinge **10.000 boletos** ou a cada **500ms**, um lote Ã© processado e enviado ao Kafka.

**BenefÃ­cios:**
- Reduz drasticamente o nÃºmero de chamadas ao Kafka
- Melhora o throughput geral do sistema
- Diminui a latÃªncia de rede atravÃ©s de batching

### 2. **Virtual Threads (Project Loom)**

Habilitado atravÃ©s do Spring Boot 4.0 e Java 21, o sistema utiliza **Virtual Threads** para:
- Processar milhares de requisiÃ§Ãµes simultÃ¢neas com baixo overhead
- Reduzir o consumo de memÃ³ria comparado a threads tradicionais
- Melhorar a escalabilidade vertical da aplicaÃ§Ã£o

### 3. **Apache Kafka para Mensageria**

IntegraÃ§Ã£o com Kafka para:
- **Desacoplamento**: SeparaÃ§Ã£o entre recepÃ§Ã£o e processamento de boletos
- **ResiliÃªncia**: Mensagens persistidas em disco
- **Escalabilidade**: Possibilidade de mÃºltiplos consumidores
- **OtimizaÃ§Ãµes**: CompressÃ£o LZ4, batching automÃ¡tico, e configuraÃ§Ãµes de performance

### 4. **API RESTful**

Endpoints HTTP para:
- Registrar novos boletos
- Monitorar o tamanho do buffer interno
- Verificar saÃºde do sistema

---

## ğŸ—ï¸ Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Cliente   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ HTTP POST
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ BoletoController    â”‚
â”‚  (REST API)         â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  BoletoService      â”‚
â”‚  - Buffer (Queue)   â”‚â—„â”€â”€â”€â”€ Scheduled Task (500ms)
â”‚  - Batch Processing â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Apache Kafka       â”‚
â”‚  Topic: boletos-    â”‚
â”‚  registro           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Fluxo de Processamento

1. **RecepÃ§Ã£o**: Cliente envia boleto via `POST /api/boletos`
2. **Buffering**: Boleto Ã© adicionado ao buffer concorrente
3. **Trigger**: Processamento ocorre quando:
   - Buffer atinge 10.000 itens, OU
   - Timer de 500ms dispara
4. **Batching**: AtÃ© 10.000 boletos sÃ£o removidos do buffer
5. **Envio**: Lote Ã© enviado ao Kafka com otimizaÃ§Ãµes de rede
6. **ConfirmaÃ§Ã£o**: Cliente recebe `202 Accepted` imediatamente

---

## ğŸ› ï¸ Tecnologias Utilizadas

| Tecnologia | VersÃ£o | Finalidade |
|------------|--------|------------|
| **Java** | 21 | Linguagem base com Virtual Threads |
| **Spring Boot** | 4.0.0 | Framework principal |
| **Spring Web MVC** | 4.0.0 | API REST |
| **Spring Kafka** | 4.0.0 | IntegraÃ§Ã£o com Apache Kafka |
| **Apache Kafka** | 7.5.0 | Message Broker |
| **Jackson** | Latest | SerializaÃ§Ã£o JSON |
| **Maven** | 3.x | Gerenciamento de dependÃªncias |
| **Docker Compose** | - | OrquestraÃ§Ã£o de containers |

---

## ğŸ“¦ PrÃ©-requisitos

- **Java 21** ou superior
- **Maven 3.6+**
- **Docker** e **Docker Compose** (para Kafka)
- **Git** (opcional)

---

## ğŸš€ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

### 1. Clone o RepositÃ³rio

```bash
git clone <url-do-repositorio>
cd gemini-regsitro-boleto
```

### 2. Inicie o Kafka com Docker Compose

```bash
docker-compose up -d
```

Isso iniciarÃ¡:
- **Zookeeper** na porta `2181`
- **Kafka** na porta `9092`

### 3. Compile o Projeto

```bash
./mvnw clean install
```

### 4. Execute a AplicaÃ§Ã£o

```bash
./mvnw spring-boot:run
```

A aplicaÃ§Ã£o estarÃ¡ disponÃ­vel em: `http://localhost:8080`

---

## ğŸ’» Como Usar

### Registrar um Boleto

**Endpoint:** `POST /api/boletos`

**Payload de Exemplo:**

```json
{
  "pagador": "JoÃ£o Silva",
  "documento": "12345678900",
  "valor": 150.00,
  "dataVencimento": "2023-12-31",
  "codigoBarras": "34191.79001.01043.510047.91020.480005"
}
```

**Comando cURL:**

```bash
curl -X POST http://localhost:8080/api/boletos \
  -H "Content-Type: application/json" \
  -d @payload.json
```

**Resposta:**
- **Status:** `202 Accepted`
- **Body:** Vazio

### Verificar Tamanho do Buffer

**Endpoint:** `GET /api/boletos/buffer-size`

```bash
curl http://localhost:8080/api/boletos/buffer-size
```

**Resposta:**
```json
1523
```

---

## ğŸ“¡ API Endpoints

| MÃ©todo | Endpoint | DescriÃ§Ã£o | Request Body | Response |
|--------|----------|-----------|--------------|----------|
| `POST` | `/api/boletos` | Registra um novo boleto | `BoletoDTO` | `202 Accepted` |
| `GET` | `/api/boletos/buffer-size` | Retorna quantidade de boletos no buffer | - | `Integer` |

### Modelo de Dados: BoletoDTO

```java
{
  "pagador": "String",        // Nome do pagador
  "documento": "String",      // CPF/CNPJ
  "valor": "BigDecimal",      // Valor do boleto
  "dataVencimento": "LocalDate", // Data de vencimento (YYYY-MM-DD)
  "codigoBarras": "String"    // CÃ³digo de barras do boleto
}
```

---

## âš¡ OtimizaÃ§Ãµes de Performance

### 1. **Virtual Threads**

```yaml
spring:
  threads:
    virtual:
      enabled: true
```

- Permite processar milhares de requisiÃ§Ãµes simultÃ¢neas
- Reduz overhead de context switching
- Melhor utilizaÃ§Ã£o de CPU

### 2. **Kafka Producer Optimizations**

```yaml
spring:
  kafka:
    producer:
      properties:
        linger.ms: 5           # Aguarda 5ms para agrupar mensagens
        batch.size: 32768      # Lote de atÃ© 32KB
        compression.type: lz4  # CompressÃ£o rÃ¡pida
        acks: 1                # ConfirmaÃ§Ã£o apenas do lÃ­der
```

**Impacto:**
- **linger.ms**: Agrupa mÃºltiplas mensagens em um Ãºnico envio de rede
- **batch.size**: Maximiza utilizaÃ§Ã£o de banda
- **compression.type**: Reduz trÃ¡fego de rede em ~70%
- **acks=1**: Balanceamento entre velocidade e durabilidade

### 3. **Batch Processing**

```java
private static final int BATCH_SIZE = 10000;

@Scheduled(fixedDelay = 500)
public synchronized void processarLote() {
    // Processa atÃ© 10.000 boletos de uma vez
}
```

**BenefÃ­cios:**
- Reduz chamadas ao Kafka de N para N/10000
- Melhora throughput em atÃ© 100x
- Diminui latÃªncia de rede

### 4. **Buffer Concorrente**

```java
private final Queue<BoletoDTO> buffer = new ConcurrentLinkedQueue<>();
```

- Thread-safe sem locks explÃ­citos
- Alta performance em cenÃ¡rios de alta concorrÃªncia
- Baixo overhead de sincronizaÃ§Ã£o

---

## ğŸ“ Estrutura do Projeto

```
gemini-regsitro-boleto/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main/
â”‚   â”‚   â”œâ”€â”€ java/com/example/boleto/
â”‚   â”‚   â”‚   â”œâ”€â”€ Application.java          # Classe principal
â”‚   â”‚   â”‚   â”œâ”€â”€ BoletoController.java     # REST Controller
â”‚   â”‚   â”‚   â”œâ”€â”€ BoletoDTO.java            # Data Transfer Object
â”‚   â”‚   â”‚   â”œâ”€â”€ BoletoService.java        # LÃ³gica de negÃ³cio
â”‚   â”‚   â”‚   â””â”€â”€ KafkaConfig.java          # ConfiguraÃ§Ã£o Kafka
â”‚   â”‚   â””â”€â”€ resources/
â”‚   â”‚       â””â”€â”€ application.yaml          # ConfiguraÃ§Ãµes da aplicaÃ§Ã£o
â”‚   â””â”€â”€ test/
â”‚       â””â”€â”€ java/com/example/boleto/
â”‚           â””â”€â”€ ApplicationTests.java     # Testes
â”œâ”€â”€ docker-compose.yml                    # Kafka + Zookeeper
â”œâ”€â”€ payload.json                          # Exemplo de payload
â”œâ”€â”€ pom.xml                               # DependÃªncias Maven
â””â”€â”€ README.md                             # Este arquivo
```

---

## âš™ï¸ ConfiguraÃ§Ãµes

### application.yaml

```yaml
server:
  port: 8080
  tomcat:
    threads:
      max: 200  # Threads do Tomcat (com Virtual Threads, nÃ£o precisa de muitas)

spring:
  application:
    name: high-throughput-boleto
  
  threads:
    virtual:
      enabled: true  # Habilita Virtual Threads (Java 21)
  
  kafka:
    bootstrap-servers: localhost:9092
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer
      properties:
        linger.ms: 5
        batch.size: 32768
        compression.type: lz4
        acks: 1
```

### VariÃ¡veis de Ambiente (Opcional)

VocÃª pode sobrescrever configuraÃ§Ãµes via variÃ¡veis de ambiente:

```bash
export SPRING_KAFKA_BOOTSTRAP_SERVERS=kafka-server:9092
export SERVER_PORT=8081
```

---

## ğŸ“Š Monitoramento e Logs

### Logs da AplicaÃ§Ã£o

O sistema registra logs importantes:

```
### Processando lote de 10000 boletos
```

### Verificar Kafka

**Listar tÃ³picos:**
```bash
docker exec -it <kafka-container-id> kafka-topics --list --bootstrap-server localhost:9092
```

**Consumir mensagens:**
```bash
docker exec -it <kafka-container-id> kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic boletos-registro \
  --from-beginning
```

---

## ğŸ§ª Testes

### Executar Testes

```bash
./mvnw test
```

### Teste de Carga (Exemplo)

Use ferramentas como **Apache JMeter**, **Gatling** ou **k6** para simular alto volume:

```bash
# Exemplo com curl em loop
for i in {1..100000}; do
  curl -X POST http://localhost:8080/api/boletos \
    -H "Content-Type: application/json" \
    -d @payload.json &
done
```

---

## ğŸ”§ Troubleshooting

### Kafka nÃ£o estÃ¡ acessÃ­vel

**Erro:** `Connection refused: localhost:9092`

**SoluÃ§Ã£o:**
```bash
docker-compose ps  # Verificar se containers estÃ£o rodando
docker-compose up -d  # Reiniciar se necessÃ¡rio
```

### OutOfMemoryError

**SoluÃ§Ã£o:** Aumentar heap da JVM:
```bash
export MAVEN_OPTS="-Xmx2g"
./mvnw spring-boot:run
```

### EvidÃªncias
![alt text](image.png)

### Buffer crescendo indefinidamente

**Causa:** Kafka nÃ£o estÃ¡ consumindo mensagens rÃ¡pido o suficiente

**SoluÃ§Ã£o:**
- Adicionar mais partiÃ§Ãµes ao tÃ³pico
- Escalar consumidores
- Aumentar `batch.size` e `linger.ms`

---

## ğŸš€ Melhorias Futuras

- [ ] Implementar persistÃªncia em banco de dados (PostgreSQL/MySQL)
- [ ] Adicionar Dead Letter Queue (DLQ) para mensagens com erro
- [ ] Implementar retry automÃ¡tico com backoff exponencial
- [ ] Adicionar mÃ©tricas com Micrometer/Prometheus
- [ ] Implementar health checks customizados
- [ ] Adicionar autenticaÃ§Ã£o e autorizaÃ§Ã£o (Spring Security)
- [ ] Criar dashboard de monitoramento (Grafana)
- [ ] Implementar testes de integraÃ§Ã£o com Testcontainers
- [ ] Adicionar documentaÃ§Ã£o OpenAPI/Swagger
- [ ] Implementar circuit breaker (Resilience4j)

---

## ğŸ“ LicenÃ§a

Este projeto Ã© um exemplo educacional e estÃ¡ disponÃ­vel para uso livre.

---

## ğŸ‘¥ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Por favor:

1. FaÃ§a um fork do projeto
2. Crie uma branch para sua feature (`git checkout -b feature/MinhaFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Adiciona MinhaFeature'`)
4. Push para a branch (`git push origin feature/MinhaFeature`)
5. Abra um Pull Request

---




## ğŸ“§ Contato

Para dÃºvidas ou sugestÃµes, abra uma issue no repositÃ³rio.

---

**Desenvolvido com â˜• e Spring Boot**
